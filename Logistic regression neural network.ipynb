{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e65e67",
   "metadata": {},
   "source": [
    "# Logistic regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ab513",
   "metadata": {},
   "source": [
    "#Convert the data to usable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c295d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For raw images in a dataset use the following code:\n",
    "\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = load dataset()\n",
    "\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff079763",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flattened = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "\n",
    "#Standardise the flattened feature values\n",
    "\n",
    "X_train = X_train_flattened/255\n",
    "X_test = X_test_flattened/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e29e0",
   "metadata": {},
   "source": [
    "#Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73cf4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f156a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_wb(dim):\n",
    "    w = np.zeroes((dim, 1))\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8060e3e",
   "metadata": {},
   "source": [
    "#Forward and backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8353e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    l = X.shape[1]\n",
    "    z = np.dot(w.T, X) + b\n",
    "    a = sigmoid(z)\n",
    "    \n",
    "    #Compute cost\n",
    "    cost = -(1/l)[np.sum(Y*np.log(a) - (1-Y)*np.log(1-A))]\n",
    "    \n",
    "    #Backward propagation\n",
    "    dz = (1/l)*(A-Y)\n",
    "    dw = np.dot(X, dz.T)\n",
    "    db = np.sum(dz)\n",
    "    \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa14f4",
   "metadata": {},
   "source": [
    "#Optimization using gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc052cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w,b,X,y,n_iter,learning_rate):\n",
    "    costs=[]\n",
    "    for i in range(n_iter):\n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        if (i%50 == 0):\n",
    "            costs.append(cost)\n",
    "    params = {\"w\": w, \"b\": b}\n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, grads, costs = optimize(w,b,X_train, Y_train, num_iterations=1000, learning rate=0.009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f4f4a",
   "metadata": {},
   "source": [
    "#Predicting final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aef27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,X):\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    a = sigmoid(np.dot(w.T, X)+b)\n",
    "    n = ['Yes' if (a>0.5) else 'No']\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbea95d",
   "metadata": {},
   "source": [
    "#Assembling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de45f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, n_iter, learning rate):\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, n_iter, learning_rate)\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    Y_prediction_test = predict(w,b,X_test)\n",
    "    Y_prediction_train = predict(w,b,X_train)   \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": n_iter}\n",
    "    return d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
